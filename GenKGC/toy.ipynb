{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(\"roberta-large\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def _read_tsv(cls, input_file, quotechar=None):\n",
    "    \"\"\"Reads a tab separated value file.\"\"\"\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
    "        lines = []\n",
    "        for line in reader:\n",
    "            if sys.version_info[0] == 2:\n",
    "                line = list(unicode(cell, 'utf-8') for cell in line)\n",
    "            lines.append(line)\n",
    "        return lines\n",
    "\n",
    "lines = _read_tsv(\"_\", \"dataset/WN18RR/test.tsv\")\n",
    "\n",
    "import random\n",
    "random.shuffle(lines)\n",
    "len_lines = len(lines)\n",
    "\n",
    "for i in range(0,10):\n",
    "    with open(f\"dataset/WN18RR/test{i+1}.tsv\", \"w\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f, delimiter=\"\\t\")\n",
    "        writer.writerows(lines[int(len_lines/10)*i : int(len_lines/10)*(i+1) if i != 9 else len_lines])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from models import KGBERTGetLabelWord\n",
    "from lit_models import TransformerLitModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = KGBERTGetLabelWord.from_pretrained(\"bert-base-uncased\")\n",
    "model_path = \"/home/xx/AI/kgc/output/epoch=3-Eval\\/acc=0.00-v1.ckpt\"\n",
    "hhmodel = TransformerLitModel(args={}, model=model)\n",
    "hhmodel.load_state_dict(torch.load(model_path)['state_dict'])\n",
    "model = hhmodel.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the FB15K237 test set\n",
    "\n",
    "with open(\"./dataset/FB15k-237/test.tsv\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(666)\n",
    "random.shuffle(lines)\n",
    "\n",
    "\n",
    "with open(\"./dataset/FB15k-237/selected_test.tsv\", \"w\") as file:\n",
    "    file.writelines(lines[:2000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert umls dataset to the openKE format\n",
    "\n",
    "# create the entity2id.txt\n",
    "\n",
    "with open(\"./dataset/umls/entities.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "with open(\"./dataset/umls/entity2id.txt\", \"w\") as file:\n",
    "    total = len(lines)\n",
    "    cnt = 0\n",
    "    file.write(f\"{total}\\n\")\n",
    "    for line in lines:\n",
    "        line = line.replace(\"\\n\",\"\")\n",
    "        file.write(f\"{line}\\t{cnt}\\n\")\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the relation2id.txt\n",
    "\n",
    "with open(\"./dataset/umls/relations.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "with open(\"./dataset/umls/relation2id.txt\", \"w\") as file:\n",
    "    total = len(lines)\n",
    "    cnt = 0\n",
    "    file.write(f\"{total}\\n\")\n",
    "    for line in lines:\n",
    "        line = line.replace(\"\\n\",\"\")\n",
    "        file.write(f\"{line}\\t{cnt}\\n\")\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make constran.txt\n",
    "\n",
    "with open(\"./dataset/umls/relation2id.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    num_relation = int(lines[0])\n",
    "with open(\"./dataset/umls/relation2id.txt\", \"r\") as file:\n",
    "    line = file.readlines()[0]\n",
    "    num_entity = int(line)\n",
    "\n",
    "with open(\"./dataset/type_constrain.txt\", \"w\") as file:\n",
    "    file.write(f\"{num_relation}\\n\")\n",
    "    l = \"\\t\".join([str(_) for _ in range(num_entity)])\n",
    "    for i in range(num_relation):\n",
    "        file.write(f\"{i}\\t{l}\\n\")\n",
    "        file.write(f\"{i}\\t{l}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MBartConfig' object has no attribute 'preseqlen'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c90f95de8e37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_bos_token_to_be_generated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda:1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AI/kgc_nlg/transformers/modeling_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m             return MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING[type(config)].from_pretrained(\n\u001b[0m\u001b[1;32m   1079\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m             )\n",
      "\u001b[0;32m~/AI/kgc_nlg/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;31m# Instantiate model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfrom_tf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AI/kgc_nlg/transformers/modeling_bart.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         print('Init the BartForConditionalGeneration Model with config.use_prefix={}, '\n\u001b[0;32m-> 1362\u001b[0;31m               'config.preseqlen={}'.format(config.use_prefix, config.preseqlen))\n\u001b[0m\u001b[1;32m   1363\u001b[0m         \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBartModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MBartConfig' object has no attribute 'preseqlen'"
     ]
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, AutoTokenizer, GPT2LMHeadModel, BartModel, T5ForConditionalGeneration,AutoModelForSeq2SeqLM, AutoConfig\n",
    "import torch\n",
    "import csv\n",
    "# model = GPT2LMHeadModel.from_pretrained(\"gpt2-medium\")\n",
    "model_name_or_path = \"facebook/mbart-large-cc25\"\n",
    "config = AutoConfig.from_pretrained(\"facebook/mbart-large-cc25\")\n",
    "config.use_prefix = False\n",
    "config.force_bos_token_to_be_generated = True\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, config=config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "device = \"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "def get_mask_word(text, model, tokenizer):\n",
    "    origin_tokens = text.split()\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    inputs = {k:v.to(device) for k,v in inputs.items()}\n",
    "    output = model.generate(\n",
    "        **inputs, \n",
    "        num_beams=10,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    _txt = tokenizer.decode(output[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "    # for t in origin_tokens:\n",
    "    #     _txt = _txt.replace(t, \"<e>\")\n",
    "    return _txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.force_bos_token_to_be_generated = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mask_word(\"<mask> says I love Japan. But <mask>\", model, tokenizer)\n",
    "from data.processor import KGProcessor\n",
    "processor = KGProcessor()\n",
    "path = \"dataset/umls\"\n",
    "examples = processor.get_train_examples(path)\n",
    "# inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "relation2pattern = defaultdict(list)\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "i = 0\n",
    "for example in tqdm(examples):\n",
    "    i += 1\n",
    "    if i%2: continue\n",
    "    head,relation,tail = example.text_a,example.text_b,example.text_c\n",
    "    text = \" <mask> \" + head + \" <mask> \" + relation + \" <mask> \" + tail + \" <mask> \"\n",
    "    p = get_mask_word(text, model, tokenizer)\n",
    "    p = re.sub(' +', '', p)\n",
    "    for t_ in [head, relation, tail]:\n",
    "        p = p.replace(t_, \"\\t\")\n",
    "    p = re.sub(' +', '', p)\n",
    "    relation2pattern[relation].append(p)\n",
    "\n",
    "for k in relation2pattern.keys():\n",
    "    relation2pattern[k] = Counter(relation2pattern[k])\n",
    "\n",
    "import pickle \n",
    "import os\n",
    "with open(os.path.join(path, \"cached_relation_pattern.pkl\"), \"wb\") as file:\n",
    "    pickle.dump(relation2pattern, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = {}\n",
    "for k,v in relation2pattern.items():\n",
    "    t = v.most_common(1)[0][0]\n",
    "    t = [_.strip() for _ in t.split(\"\\t\")]\n",
    "    t[-1] = \" .\"\n",
    "    print(k)\n",
    "    print(t)\n",
    "    pattern[k] = t\n",
    "    assert len(t) ==4\n",
    "\n",
    "with open(os.path.join(path, \"cached_relation_pattern.pkl\"), \"wb\") as file:\n",
    "    pickle.dump(pattern, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.trie import Trie\n",
    "\n",
    "label_sequence = [\"ceo\", \"founder\", \"new ceo\"]\n",
    "# label_sequence_ids = tokenizer(label_sequence, add_special_tokens=T).input_ids\n",
    "# trie = Trie([[0, 32099] + _ +[32100] for _ in label_sequence_ids])\n",
    "# print(label_sequence_ids)\n",
    "from models.utils import get_entity_spans_pre_processing\n",
    "from models.trie import get_end_to_end_prefix_allowed_tokens_fn_hf\n",
    "mention_trie = Trie([[2] + tokenizer(\" type Movie\").input_ids])\n",
    "entity_trie = Trie([[2] + tokenizer(\"type Movie\").input_ids])\n",
    "input_sentences = [\"Steve Jobs is the <mask> of Apple.\"]\n",
    "inputs = tokenizer(\"Steve Jobs is the <mask> of {Apple}.\", return_tensors='pt')\n",
    "prefix_allowed_tokens_fn = get_end_to_end_prefix_allowed_tokens_fn_hf(\n",
    "            tokenizer=tokenizer,\n",
    "            sentences=get_entity_spans_pre_processing(input_sentences),\n",
    "            mention_trie=mention_trie,\n",
    "            candidates_trie=entity_trie\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试模型在mask上的输出能力\n",
    "inputs = tokenizer(\" <mask> genre  Romance Film\", return_tensors=\"pt\")\n",
    "model.force_bos_token_to_be_generated = True\n",
    "outputs = model.generate(**inputs,\n",
    "prefix_allowed_tokens_fn=lambda batch_id, sent: entity_trie.get(sent.tolist()),\n",
    "num_beams=200,\n",
    "        num_return_sequences=1,\n",
    "        max_length=40,\n",
    "forced_bos_token_id=tokenizer.bos_token_id,\n",
    ")\n",
    "print(outputs)\n",
    "print(tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(outputs[0])))\n",
    "outputs = model.generate(**inputs,\n",
    "forced_bos_token_id=tokenizer.bos_token_id,\n",
    ")\n",
    "print(outputs)\n",
    "print(tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(outputs[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_filling(text, model, tokenizer, fn, device=\"cpu\"):\n",
    "    def decode(output_ids):\n",
    "        return [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in output_ids]\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    model = model.to(device)\n",
    "    prefix_output = model.generate(\n",
    "        **inputs,\n",
    "        prefix_allowed_tokens_fn=fn,\n",
    "        forced_bos_token_id=tokenizer.bos_token_id,\n",
    "    )\n",
    "    origin_output = model.generate(\n",
    "        **inputs,\n",
    "        num_beams=20,\n",
    "        num_return_sequences=1,\n",
    "        forced_bos_token_id=tokenizer.bos_token_id,\n",
    "    )\n",
    "    print(\"prefix output: \\t\", prefix_output)\n",
    "    print(\"prefix output token: \\y\" + decode(prefix_output)[0])\n",
    "    print(\"output: \",  origin_output)\n",
    "    print(\"output token: \" + decode(origin_output)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_text = [\" type Movie\", \" type type\"]\n",
    "entity_trie = Trie(\n",
    "    [\n",
    "    [tokenizer.eos_token_id] + _ for _ in tokenizer(label_text).input_ids\n",
    "]\n",
    ")\n",
    "prefix_allowed_tokens_fn=lambda batch_id, sent: entity_trie.get(sent.tolist())\n",
    "mask_filling(\"Southern California often abbreviated as SoCal . Southern California often abbreviated as <mask> .\", model, tokenizer, prefix_allowed_tokens_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in entity_trie:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./dataset/SST-2/test.tsv\"\n",
    "examples = []\n",
    "with open(path, \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        label = line.split(\" \", 1)[0]\n",
    "        text = line.split(\" \", 1)[1]\n",
    "        examples.append(dict(labels=label, text=text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "attention_mask = []\n",
    "labels = []\n",
    "for example in examples:\n",
    "    inputs = tokenizer(\n",
    "        example['text'],\n",
    "        truncation=\"longest_first\",\n",
    "        max_length=128,\n",
    "        padding=\"max_length\",\n",
    "        add_special_tokens=True,\n",
    "    )\n",
    "    input_ids.append(inputs.input_ids)\n",
    "    attention_mask.append(inputs.attention_mask)\n",
    "    labels.append(example['labels'])\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "input_ids = torch.tensor(input_ids)\n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "labels = torch.tensor([int(_) for _ in labels])\n",
    "dataset = TensorDataset(input_ids, attention_mask, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = []\n",
    "device = \"cuda:1\"\n",
    "labels = []\n",
    "model = model.to(device).eval()\n",
    "for batch in dataloader:\n",
    "    batch = [_.to(device) for _ in batch]\n",
    "    inputs = dict(input_ids=batch[0], attention_mask=batch[1])\n",
    "    outputs = model.generate(**inputs, prefix_allowed_tokens_fn=lambda batch_id, sent: trie.get(sent.tolist()),\n",
    "        num_beams=200,\n",
    "        num_return_sequences=1,\n",
    "        max_length=10\n",
    "    )\n",
    "    print(outputs[0])\n",
    "    for o in outputs:\n",
    "        if torch.equal(torch.tensor([2, 100, 206, 24, 16, 6587, 2]).to(device), o[:10]):\n",
    "            model_output += [0]\n",
    "        else:\n",
    "            model_output += [1]\n",
    "    labels += batch[2].detach().cpu().tolist()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for a,b in zip(model_output, labels):\n",
    "    if a == b: cnt += 1\n",
    "print(cnt / len(model_output)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer\n",
    "model.force_bos_token_to_be_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import BartTokenizer, BartForCausalLM\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "model = BartForCausalLM.from_pretrained('facebook/bart-base', add_cross_attention=False)\n",
    "assert model.config.is_decoder, f\"{model.__class__} has to be configured as a decoder.\"\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5Config, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "T5_PATH = 't5-large' # \"t5-small\", \"t5-base\", \"t5-large\", \"t5-3b\", \"t5-11b\"\n",
    "\n",
    "DEVICE = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu') # My envirnment uses CPU\n",
    "\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(T5_PATH)\n",
    "t5_config = T5Config.from_pretrained(T5_PATH)\n",
    "t5_mlm = T5ForConditionalGeneration.from_pretrained(T5_PATH, config=t5_config).to(DEVICE)\n",
    "\n",
    "# Input text\n",
    "\n",
    "def get_words(text,):\n",
    "    # text = 'Who is the founder of Huawei? It is <extra_id_0> .'\n",
    "\n",
    "    encoded = t5_tokenizer.encode_plus(text, add_special_tokens=True, return_tensors='pt')\n",
    "    input_ids = encoded['input_ids'].to(DEVICE)\n",
    "\n",
    "    # Generaing 20 sequences with maximum length set to 5\n",
    "    outputs = t5_mlm.generate(input_ids=input_ids, \n",
    "                            num_beams=200, num_return_sequences=20,\n",
    "                            max_length=10)\n",
    "\n",
    "    _0_index = text.index('<extra_id_0>')\n",
    "    _result_prefix = text[:_0_index]\n",
    "    _result_suffix = text[_0_index+12:]  # 12 is the length of <extra_id_0>\n",
    "\n",
    "    def _filter(output, end_token='<extra_id_1>'):\n",
    "        # The first token is <unk> (inidex at 0) and the second token is <extra_id_0> (indexed at 32099)\n",
    "        _txt = t5_tokenizer.decode(output[2:], skip_special_tokens=False, clean_up_tokenization_spaces=False)\n",
    "        if end_token in _txt:\n",
    "            _end_token_index = _txt.index(end_token)\n",
    "            return _txt[:] \n",
    "        else:\n",
    "            return _result_prefix + _txt + _result_suffix\n",
    "\n",
    "    results = list(map(_filter, outputs))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "get_words(\"<extra_id_0> work, prepare for crops; \\\"Work the soil\\\"; \\\"cultivate the land\\\" <extra_id_1> verb group <extra_id_2> work, make uniform; \\\"knead dough\\\"; \\\"work the clay until it is soft <extra_id_3>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model in the SQUAD\n",
    "samples = []\n",
    "import json\n",
    "with open(\"./dataset/LAMA/Squad/test.jsonl\", \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        t = json.loads(line)\n",
    "        samples.append(dict(text=t['masked_sentences'][0], label=t['obj_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get precision@10\n",
    "\n",
    "num_samples = len(samples)\n",
    "cnt = 0\n",
    "from tqdm import tqdm\n",
    "for s in tqdm(samples):\n",
    "    # a = get_words(s['text'].replace(\"[MASK]\", \"<extra_id_0>\"))\n",
    "    # result = [aa.split(\"<extra_id_1>\")[0].strip() for aa in a[0:1]]\n",
    "    txt = get_mask_word(s['text'].replace(\"[MASK]\", \"<mask>\"), model, tokenizer)\n",
    "    if s['label'] in txt:\n",
    "        cnt += 1\n",
    "print(cnt / num_samples)\n",
    "# print(samples[0]['label'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(\"facebook/mbart-large-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./dataset/FB15k-237\"\n",
    "import pickle\n",
    "with open(os.path.join(path, \"cached_relation_pattern.pkl\"), \"rb\") as file:\n",
    "    a = pickle.load(file)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in a.items():\n",
    "    print(k)\n",
    "    print(v.most_common(1)[0][0].split(\"\\t\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Can't load config for 'Helsinki-NLP/opus-tatoeba-en-ja'. Make sure that:\n\n- 'Helsinki-NLP/opus-tatoeba-en-ja' is a correct model identifier listed on 'https://huggingface.co/models'\n\n- or 'Helsinki-NLP/opus-tatoeba-en-ja' is the correct path to a directory containing a config.json file\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m~/AI/kgc_nlg/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresolved_config_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             \u001b[0mconfig_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dict_from_json_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_config_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b8682594f2d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda:1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Helsinki-NLP/opus-tatoeba-en-ja\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Helsinki-NLP/opus-tatoeba-en-ja\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AI/kgc_nlg/transformers/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"bert-base-japanese\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AI/kgc_nlg/transformers/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0;34m'foo'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AI/kgc_nlg/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m                 \u001b[0;34mf\"- or '{pretrained_model_name_or_path}' is the correct path to a directory containing a {CONFIG_NAME} file\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             )\n\u001b[0;32m--> 368\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load config for 'Helsinki-NLP/opus-tatoeba-en-ja'. Make sure that:\n\n- 'Helsinki-NLP/opus-tatoeba-en-ja' is a correct model identifier listed on 'https://huggingface.co/models'\n\n- or 'Helsinki-NLP/opus-tatoeba-en-ja' is the correct path to a directory containing a config.json file\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "  \n",
    "device = \"cuda:1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-tatoeba-en-ja\")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-tatoeba-en-ja\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "with open(\"./dataset/wikidata5m/entity2text.txt\", \"r\") as file:\n",
    "    lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "text2id = {}\n",
    "cnt = 0\n",
    "total = []\n",
    "for line in lines:\n",
    "    t = line.strip().split(\"\\t\")[0]\n",
    "    assert \"Q\" in t\n",
    "    total.append(t)\n",
    "print(cnt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Q5196650',\n",
       " 'Q912600',\n",
       " 'Q47551',\n",
       " 'Q5460288',\n",
       " 'Q1138408',\n",
       " 'Q18151267',\n",
       " 'Q17981446',\n",
       " 'Q7562391',\n",
       " 'Q805099',\n",
       " 'Q4621073',\n",
       " 'Q1787023',\n",
       " 'Q6180728',\n",
       " 'Q471108',\n",
       " 'Q54319',\n",
       " 'Q772555',\n",
       " 'Q639978',\n",
       " 'Q5764645',\n",
       " 'Q837573',\n",
       " 'Q6291502',\n",
       " 'Q20899554',\n",
       " 'Q4019621',\n",
       " 'Q947890',\n",
       " 'Q25460298',\n",
       " 'Q160698',\n",
       " 'Q7777598',\n",
       " 'Q24391822',\n",
       " 'Q720504',\n",
       " 'Q1363733',\n",
       " 'Q3595742',\n",
       " 'Q19801909',\n",
       " 'Q739564',\n",
       " 'Q524519',\n",
       " 'Q292350',\n",
       " 'Q6116949',\n",
       " 'Q2752724',\n",
       " 'Q58029',\n",
       " 'Q6517739',\n",
       " 'Q818606',\n",
       " 'Q7574735',\n",
       " 'Q1113636',\n",
       " 'Q3898485',\n",
       " 'Q4191870',\n",
       " 'Q137443',\n",
       " 'Q20937',\n",
       " 'Q11316743',\n",
       " 'Q7243478',\n",
       " 'Q314646',\n",
       " 'Q15139463',\n",
       " 'Q7430529',\n",
       " 'Q2109972',\n",
       " 'Q4761155',\n",
       " 'Q1269170',\n",
       " 'Q7232462',\n",
       " 'Q2387770',\n",
       " 'Q5818907',\n",
       " 'Q154701',\n",
       " 'Q7107088',\n",
       " 'Q6623135',\n",
       " 'Q1184780',\n",
       " 'Q17076813',\n",
       " 'Q4950648',\n",
       " 'Q4115894',\n",
       " 'Q5384577',\n",
       " 'Q6819242',\n",
       " 'Q6456627',\n",
       " 'Q838757',\n",
       " 'Q2740039',\n",
       " 'Q6929907',\n",
       " 'Q1086888',\n",
       " 'Q188673',\n",
       " 'Q16859336',\n",
       " 'Q12800734',\n",
       " 'Q1157112',\n",
       " 'Q6554199',\n",
       " 'Q2438969',\n",
       " 'Q2057747',\n",
       " 'Q16824537',\n",
       " 'Q13572471',\n",
       " 'Q4777188',\n",
       " 'Q3026456',\n",
       " 'Q23542600',\n",
       " 'Q27811386',\n",
       " 'Q6571683',\n",
       " 'Q1991997',\n",
       " 'Q26993',\n",
       " 'Q7409735',\n",
       " 'Q6633974',\n",
       " 'Q5225372',\n",
       " 'Q17116388',\n",
       " 'Q19872000',\n",
       " 'Q441715',\n",
       " 'Q1277402',\n",
       " 'Q5296548',\n",
       " 'Q5263245',\n",
       " 'Q29561754',\n",
       " 'Q4948859',\n",
       " 'Q926359',\n",
       " 'Q19930089',\n",
       " 'Q3255165',\n",
       " 'Q290307']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mode in [\"train\", \"dev\", \"test\"]:\n",
    "    mode = mode + \".txt\"\n",
    "    path = \"./dataset/AliOpenKG500/\"+mode\n",
    "    with open(path) as file:\n",
    "        samples = file.readlines()\n",
    "\n",
    "    with open(\"./dataset/AliOpenKG500/\"+mode.replace(\"txt\",\"tsv\"), \"w\") as file:\n",
    "        for s in samples:\n",
    "            t = s.strip().split()\n",
    "            if len(t) == 1: continue\n",
    "            h,t,r = t\n",
    "            file.write('\\t'.join([h,r,t]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': '规格类型', '1': '薄厚', '2': '是否精酿', '3': '品牌', '4': '适用季节', '5': '产地', '6': '功效', '7': '安全等级', '8': '裤长', '9': '材质', '10': '鞋底材质', '11': '适用年龄', '12': '色泽', '13': '出版社名称', '14': '鞋帮高度', '15': '是否进口', '16': '适用群体', '17': '供暖方式', '18': '适用地区', '19': '成分', '20': '图案', '21': '形状', '22': '特产品类', '23': '分类', '24': '侧翼面料', '25': '样式', '26': '包装方式', '27': '功能', '28': '材质成分', '29': '版型', '30': '设计细节', '31': '裤门襟', '32': '目标人群', '33': '刀头数量', '34': '外底材质', '35': '是否为有机食品', '36': '裤子分类', '37': '组合形式', '38': '安装方式', '39': '口味', '40': '热水器燃气类型', '41': '保质期', '42': '支数', '43': '颜色分类', '44': '产品类别', '45': '表扣款式', '46': '袖长', '47': '填充料', '48': '适用场景', '49': '适用面积', '50': '款式品名', '51': '部位', '52': '领型', '53': '是否带壳', '54': '成分含量', '55': '服装款式细节', '56': '表壳材质', '57': '内文用纸材质', '58': '是否手工', '59': '品牌类型', '60': '毛色', '61': '包装', '62': '帮面材质', '63': '成色', '64': '系列', '65': '贴纸类型', '66': '设计元素', '67': '品牌归属地', '68': '条数', '69': '地市', '70': '添加剂', '71': '流行元素', '72': '质地', '73': '净含量', '74': '衣门襟', '75': '套装类型', '76': '袖型', '77': '大小', '78': '玩具类型', '79': '开口深度', '80': '是否有机', '81': '供电方式', '82': '种类', '83': '服装版型', '84': '是否带帽子', '85': '面料', '86': '级别', '87': '运动鞋科技', '88': '印花主题', '89': '面料材质', '90': '套餐周期', '91': '销售渠道类型', '92': '是否是套装', '93': '产品重量', '94': '是否自动', '95': '储存条件', '96': '基础风格', '97': '网络类型', '98': '是否礼盒装', '99': '是否商场同款', '100': '鞋垫材质', '101': '鞋跟款式', '102': '上市年份季节', '103': '是否转基因', '104': '腰型', '105': '裙长', '106': '佩戴方式', '107': '薯制品种类', '108': '有无钢托', '109': '食品工艺', '110': '是否淘品牌', '111': '里料材质', '112': '书写粗细', '113': '奶源种类', '114': '运动户外项目', '115': '包装形式', '116': '上市时间', '117': '肩带样式', '118': '裤脚口款式', '119': '服饰工艺', '120': '适用肤质', '121': '鞋头款式', '122': '适用阶段', '123': '防晒指数', '124': '狗狗品种', '125': '香型', '126': '尿片规格', '127': '适合季节', '128': '裙型', '129': '模特实拍', '130': '皂种类', '131': '包内部结构', '132': '参考身高', '133': '盘类型', '134': '酱菜种类', '135': '是否开裆', '136': '层数', '137': '外部材质', '138': '侧翼里料', '139': '里料图案', '140': '参种类', '141': '食品口味', '142': '科目', '143': '适用性别', '144': '适用部位', '145': '糖果种类', '146': '适用空间', '147': '收纳场景', '148': '搭扣排数', '149': '鞋码', '150': '适用人数', '151': '型号', '152': '奶粉种类', '153': '搭扣款式', '154': '衣长', '155': '教辅种类', '156': '配件种类', '157': '适用场合', '158': '笔类型', '159': '套装件数', '160': '屏幕尺寸', '161': '是否量贩装', '162': '包装规格', '163': '送风方式', '164': '鞋跟高度', '165': '是否有核', '166': '海鲜制品种类', '167': '材质', '168': '包装体积', '169': '克重', '170': '进口类型', '171': '颜色数', '172': '直径', '173': '电芯类型', '174': '功率', '175': '箱包硬度', '176': '适用发质', '177': '外壳材质', '178': '插片种类', '179': '科技', '180': '内桶材质', '181': '适合肤质', '182': '卫生棉条类型', '183': '面料织造方法', '184': '电流类型', '185': '适用场地', '186': '是否有声', '187': '产品品类', '188': '色系', '189': '智能类型', '190': '是否含糖', '191': '眼镜配件类型', '192': '文胸款式', '193': '是否开口', '194': '驱动类型', '195': '加工工艺', '196': '生产厂家', '197': '容量', '198': '是否印花', '199': '档位', '200': '廓形', '201': '酒精度数', '202': '原料成分', '203': '线材长度', '204': '电压', '205': '是否为特殊用途化妆品', '206': '是否带锁', '207': '是否有香味', '208': '加工方式', '209': '生鲜储存温度', '210': '配皮材质', '211': '是否无线', '212': '封面硬度', '213': '摆件类型', '214': '镜片度数', '215': '燃料种类', '216': '适用尺码', '217': '产品分类', '218': '出水方式', '219': '镜片尺寸', '220': '商品属性', '221': '产品等级', '222': '件数', '223': '运动鞋分类', '224': '有无夹层', '225': '具体规格', '226': '面料分类', '227': '闭合方式', '228': '鞋跟高', '229': '盆种类', '230': '品种', '231': '开本', '232': '是否带坠', '233': '演出赛事时间', '234': '版本类型', '235': '护具种类', '236': '颜色数量', '237': '动力类型', '238': '肉松种类', '239': '运动系列', '240': '保修期', '241': '高度', '242': '电机类型', '243': '煲种类', '244': '杆材质', '245': '馅料种类', '246': '纸品净含量', '247': '机芯类型', '248': '面板类型', '249': '适用时间', '250': '包装数量', '251': '蔬菜种类', '252': '省份', '253': '刷柄材质', '254': '适用送礼场合', '255': '洗水工艺', '256': '纸开本', '257': '鞋底制作工艺', '258': '售卖方式', '259': '细分风格', '260': '卫生巾厚薄', '261': '附加功能', '262': '采购地', '263': '只数', '264': '手琴类型', '265': '保温时长', '266': '模杯类型', '267': '特殊用途化妆品', '268': '排水方式', '269': '身体护理工具分类', '270': '中底材质', '271': '罩杯款式', '272': '文胸尺码', '273': '度数', '274': '桌面是否可调节', '275': '画笔类型', '276': '规格', '277': '外包装', '278': '香味', '279': '化妆品净含量', '280': '幅数', '281': '弹力', '282': '鱼肉部位', '283': '魔方种类', '284': '面条种类', '285': '单面双面', '286': '等级', '287': '适用手机型号', '288': '拉杆位置', '289': '配件数量', '290': '适用节日', '291': '锁的类型', '292': '电源方式', '293': '适配电池类型', '294': '电池类型', '295': '主题词', '296': '模杯厚度', '297': '内存扩展容量', '298': '清洗类型', '299': '裤型', '300': '宠物用品款式', '301': '适用类型', '302': '工作方式', '303': '粮食种类', '304': '接口类型', '305': '床尺寸', '306': '主题', '307': '材质工艺', '308': '防滑指数', '309': '茶种类', '310': '馅料口味', '311': '围巾分类', '312': '鞋面材质', '313': '汽车品牌', '314': '充绒量', '315': 'CPU型号', '316': '是否瑕疵', '317': '可否折叠', '318': '适用床尺寸', '319': '插片', '320': '发行地区', '321': '适合胸型', '322': '是否原装', '323': '糖种类', '324': '床垫类型', '325': '玩具材质', '326': '水果种类', '327': '滤网类型', '328': '加湿方式', '329': '挤水方式', '330': '水温要求', '331': '适用年龄段', '332': '页数', '333': '线长', '334': '套餐份量', '335': '单品', '336': '糕点种类', '337': '是否电动', '338': '年代', '339': '周长', '340': '蛋糕尺寸', '341': '内胆类型', '342': '是否有盖', '343': '笔杆材质', '344': '里料', '345': '腰带带扣款式', '346': '外帐材质', '347': '帽顶款式', '348': '豆制品种类', '349': '套件数量', '350': '酒香型', '351': '笔头规格', '352': '适用墨水类型', '353': '精油分类', '354': '车蜡类型', '355': '进水方式', '356': '刷毛材质', '357': '口罩佩戴方式', '358': '滤芯类型', '359': '颗数', '360': '运动支撑强度', '361': '面料工艺', '362': '杯型', '363': '穿线类型', '364': '记录仪安装类型', '365': '运营商', '366': '原产地', '367': '制冷方式', '368': '开关类型', '369': '模杯面料', '370': '毛领材质', '371': '手机类型', '372': '醋类型', '373': '类型', '374': '毛线粗细', '375': '玻璃杯花色', '376': '喇叭单元', '377': '牛种', '378': '刀尖角度', '379': '发动机类型', '380': '配件类型', '381': '礼服类型', '382': '前进方式', '383': '旗袍款式', '384': '镜头数量', '385': '内胆材质', '386': '生长季节', '387': '鱼制品种类', '388': '原料产地', '389': '是否组装', '390': '配送频次', '391': '是否自动充电', '392': '鞋钉种类', '393': '替芯类型', '394': '布艺帘款式', '395': '饲养方式', '396': '适用年级', '397': '储藏方法', '398': '内存容量', '399': '穿搭方式', '400': '鞋垫种类', '401': '包装种类', '402': '格数', '403': '檐形', '404': '裆部材质', '405': '排烟方式', '406': '提拎部件类型', '407': '服装下摆设计', '408': '机油分类', '409': '产品类型', '410': '动物性别', '411': '制造工艺', '412': '显示屏', '413': '键盘类型', '414': '戒指手寸', '415': '裤款式', '416': '收伞方式', '417': '地漏类型', '418': '伞面尺寸', '419': '鞋套种类', '420': '笔头毛种', '421': '瓶种类', '422': '轴承数', '423': '是否可调', '424': '图案文化', '425': '家具结构', '426': '语言', '427': '灯具是否带光源', '428': '散热方式', '429': '秤类型', '430': '装订方式', '431': '服装口袋样式', '432': '电子电工产品类型', '433': '猪肉部位', '434': '是否震动', '435': '织造工艺', '436': '奶酪种类', '437': '果径', '438': '刃长', '439': '倍率类型', '440': '消毒方式', '441': '肉类产品', '442': '进风方式', '443': '机芯种类', '444': '适用场所', '445': '侧帮款式', '446': '输入电压', '447': '后帮款式', '448': '腰带圈数', '449': '显卡类型', '450': '贵金属成色', '451': '是否带柄', '452': '产品剂型', '453': '腰带款式', '454': '有效期', '455': '开门方式', '456': '张数', '457': '饮品种类', '458': '出雾时间', '459': '笔芯颜色', '460': '宽度', '461': '装裱方式', '462': '制作工艺', '463': '雨具种类', '464': '刷头材质', '465': '大小描述', '466': '光驱类型', '467': '消毒时间', '468': '净重', '469': '酒精度', '470': '线材类型', '471': '蛋品种', '472': '承重', '473': '单双面', '474': '电话类型', '475': '适用运动', '476': '帐底材质', '477': '鸭肉部位', '478': '适用环境', '479': '周边产品', '480': '带扣材质', '481': '蛋糕种类', '482': '是否连帽', '483': '肉类品种', '484': '门数量', '485': '额定功率', '486': '显存容量', '487': '被子种类', '488': '底盘类型', '489': '语种分类', '490': '食用油类型', '491': '保鲜工艺', '492': '高度是否可调节', '493': '是否含香味', '494': '是否有开机自检', '495': '关联场景', '496': '细分市场', '497': '适用人群', '498': '关联主题', '499': '适用时间'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "total_relations = {}\n",
    "with open(\"./dataset/AliOpenKG500/relation2id.txt\") as file:\n",
    "    for line in file.readlines():\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        if len(line) == 1: continue\n",
    "        r, r_id = line\n",
    "        total_relations[r_id] = r\n",
    "\n",
    "with open(\"./dataset/AliOpenKG500/other_format/relation_map.txt\") as file:\n",
    "    for line in file.readlines():\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        r_text, r_real_name = line\n",
    "        # print(r_text)\n",
    "        for k, v in total_relations.items():\n",
    "            \n",
    "            if v == r_text:\n",
    "                total_relations[k] = r_real_name\n",
    "\n",
    "with open(\"./dataset/AliOpenKG500/relation2text.txt\", \"w\") as file:\n",
    "    for k,v in total_relations.items():\n",
    "        file.write('\\t'.join([k, v]) +'\\n')\n",
    "print(total_relations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "entity2id = {}\n",
    "relation2id = {}\n",
    "with open(\"./dataset/AliOpenKG500/entity2id.txt\") as file:\n",
    "    for line in file.readlines():\n",
    "        e_name, e_id = line.strip().split(\"\\t\")\n",
    "        entity2id[e_name] = e_id\n",
    "with open(\"./dataset/AliOpenKG500/relation2id.txt\") as file:\n",
    "    for line in file.readlines():\n",
    "        e_name, e_id = line.strip().split(\"\\t\")\n",
    "        relation2id[e_name] = e_id\n",
    "\n",
    "\n",
    "for mode in [\"train\", \"test\", \"dev\", \"test2\"]:\n",
    "    with open(f\"./dataset/AliOpenKG500/other_format/{mode}\".replace(\"dev\", \"valid\")) as file:\n",
    "        data = []\n",
    "        for line in file.readlines():\n",
    "            h,r,t = line.strip().split(\"\\t\")\n",
    "            data.append([entity2id[h], relation2id[r], entity2id[t]])\n",
    "\n",
    "    with open(f\"dataset/AliOpenKG500/{mode}.tsv\", \"w\") as file:\n",
    "        for d in data:\n",
    "            file.write(\"\\t\".join(d) + '\\n')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "test = []\n",
    "with open(\"dataset/AliOpenKG500/dev.tsv\") as file:\n",
    "    test = file.readlines()\n",
    "\n",
    "test_mini = random.sample(test, 5000)\n",
    "\n",
    "with open(\"./dataset/AliOpenKG500/dev_mini.tsv\", \"w\") as file:\n",
    "    file.writelines(test_mini)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "72340c4ad4ace40a25e03e3f9f59ab3399d64e8ae41aaaa2acd2bfb492ed770c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('openue': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
